{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3323ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee108525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#mysql_jar_path = os.path.abspath(\"mysql-connector-j-9.0.0.jar\")\n",
    "#print(\"Caminho completo do JAR:\", mysql_jar_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "785d8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "414f509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd640b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in ./venv/lib/python3.12/site-packages (0.2.61)\n",
      "Requirement already satisfied: pandas>=1.3.0 in ./venv/lib/python3.12/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in ./venv/lib/python3.12/site-packages (from yfinance) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.31 in ./venv/lib/python3.12/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in ./venv/lib/python3.12/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in ./venv/lib/python3.12/site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in ./venv/lib/python3.12/site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in ./venv/lib/python3.12/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in ./venv/lib/python3.12/site-packages (from yfinance) (3.18.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in ./venv/lib/python3.12/site-packages (from yfinance) (4.13.4)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in ./venv/lib/python3.12/site-packages (from yfinance) (0.11.1)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in ./venv/lib/python3.12/site-packages (from yfinance) (5.29.4)\n",
      "Requirement already satisfied: websockets>=13.0 in ./venv/lib/python3.12/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
      "Requirement already satisfied: cffi>=1.12.0 in ./venv/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in ./venv/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.4.26)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "944da4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "582e27cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price            Close        High         Low        Open    Volume\n",
      "Ticker            ABNB        ABNB        ABNB        ABNB      ABNB\n",
      "Date                                                                \n",
      "2020-12-10  144.710007  165.000000  141.250000  146.000000  70447500\n",
      "2020-12-11  139.250000  151.500000  135.100006  146.550003  26980800\n",
      "2020-12-14  130.000000  135.300003  125.160004  135.000000  16966100\n",
      "2020-12-15  124.800003  127.599998  121.500000  126.690002  10914400\n",
      "2020-12-16  137.990005  142.000000  124.910004  125.830002  20409600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ticker = \"ABNB\"\n",
    "data = yf.download(ticker,\n",
    "                   start=\"2018-01-01\", \n",
    "                   end=\"2020-12-31\")    \n",
    "\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ebe3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_ABNB = f\"{ticker}_ABNB_historical_train_data_spark.csv\"\n",
    "data.to_csv(csv_ABNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4284f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ABNB= pd.read_csv(\"ABNB_ABNB_historical_train_data_spark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8781aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticker</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>144.7100067138672</td>\n",
       "      <td>165.0</td>\n",
       "      <td>141.25</td>\n",
       "      <td>146.0</td>\n",
       "      <td>70447500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>139.25</td>\n",
       "      <td>151.5</td>\n",
       "      <td>135.10000610351562</td>\n",
       "      <td>146.5500030517578</td>\n",
       "      <td>26980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>130.0</td>\n",
       "      <td>135.3000030517578</td>\n",
       "      <td>125.16000366210938</td>\n",
       "      <td>135.0</td>\n",
       "      <td>16966100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Price              Close               High                 Low  \\\n",
       "0      Ticker               ABNB               ABNB                ABNB   \n",
       "1        Date                NaN                NaN                 NaN   \n",
       "2  2020-12-10  144.7100067138672              165.0              141.25   \n",
       "3  2020-12-11             139.25              151.5  135.10000610351562   \n",
       "4  2020-12-14              130.0  135.3000030517578  125.16000366210938   \n",
       "\n",
       "                Open    Volume  \n",
       "0               ABNB      ABNB  \n",
       "1                NaN       NaN  \n",
       "2              146.0  70447500  \n",
       "3  146.5500030517578  26980800  \n",
       "4              135.0  16966100  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ABNB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0749348f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-----------------+------------------+-----------------+--------+\n",
      "|     Price|            Close|             High|               Low|             Open|  Volume|\n",
      "+----------+-----------------+-----------------+------------------+-----------------+--------+\n",
      "|    Ticker|             ABNB|             ABNB|              ABNB|             ABNB|    ABNB|\n",
      "|      Date|             null|             null|              null|             null|    null|\n",
      "|2020-12-10|144.7100067138672|            165.0|            141.25|            146.0|70447500|\n",
      "|2020-12-11|           139.25|            151.5|135.10000610351562|146.5500030517578|26980800|\n",
      "|2020-12-14|            130.0|135.3000030517578|125.16000366210938|            135.0|16966100|\n",
      "+----------+-----------------+-----------------+------------------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Parar sessão anterior, se necessário\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Criar nova SparkSession com o caminho exato do JAR\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark CSV to MySQL\") \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.jars\", \"/usr/local/spark-3.4.4-bin-hadoop3/jars/mysql-connector-j-8.0.33.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Caminho do CSV\n",
    "file_path = \"file:///home/hduser/novo/ABNB_ABNB_historical_train_data_spark.csv\"\n",
    "\n",
    "# Leitura do CSV\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Visualizar as primeiras 5 linhas\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1410318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the data type info\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab506793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-----------------+------------------+-----------------+--------+\n",
      "|     Price|            Close|             High|               Low|             Open|  Volume|\n",
      "+----------+-----------------+-----------------+------------------+-----------------+--------+\n",
      "|    Ticker|             ABNB|             ABNB|              ABNB|             ABNB|    ABNB|\n",
      "|      Date|             null|             null|              null|             null|    null|\n",
      "|2020-12-10|144.7100067138672|            165.0|            141.25|            146.0|70447500|\n",
      "|2020-12-11|           139.25|            151.5|135.10000610351562|146.5500030517578|26980800|\n",
      "|2020-12-14|            130.0|135.3000030517578|125.16000366210938|            135.0|16966100|\n",
      "+----------+-----------------+-----------------+------------------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab3274be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first two lines (CRL and null)\n",
    "df = df.filter(df.Price != \"Ticker\").filter(df.Price != \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9685426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.toDF(\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3960943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------+------------------+------------------+--------+\n",
      "|      Date|             Close|             High|               Low|              Open|  Volume|\n",
      "+----------+------------------+-----------------+------------------+------------------+--------+\n",
      "|2020-12-10| 144.7100067138672|            165.0|            141.25|             146.0|70447500|\n",
      "|2020-12-11|            139.25|            151.5|135.10000610351562| 146.5500030517578|26980800|\n",
      "|2020-12-14|             130.0|135.3000030517578|125.16000366210938|             135.0|16966100|\n",
      "|2020-12-15|124.80000305175781|127.5999984741211|             121.5|126.69000244140625|10914400|\n",
      "|2020-12-16|137.99000549316406|            142.0|124.91000366210938|125.83000183105469|20409600|\n",
      "+----------+------------------+-----------------+------------------+------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d194d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35d95115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---+----+------+\n",
      "|Date|Close|High|Low|Open|Volume|\n",
      "+----+-----+----+---+----+------+\n",
      "|   0|    0|   0|  0|   0|     0|\n",
      "+----+-----+----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Count Number of nulls in all Column\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89b561a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string double\n",
    "df = df.withColumn(\"Close\", col(\"Close\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1d99cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e204efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df.withColumn(\"High\", col(\"High\").cast(\"double\"))\n",
    "df = df.withColumn(\"Low\", col(\"Low\").cast(\"double\"))\n",
    "df = df.withColumn(\"Open\", col(\"Open\").cast(\"double\"))\n",
    "df = df.withColumn(\"Volume\", col(\"Volume\").cast(\"double\"))\n",
    "df = df.withColumn(\"Date\", col(\"Date\").cast(\"Date\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5822132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- Volume: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f03d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.3.0\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "print(mysql.connector.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "581cf41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------+------------------+------------------+---------+\n",
      "|      Date|             Close|             High|               Low|              Open|   Volume|\n",
      "+----------+------------------+-----------------+------------------+------------------+---------+\n",
      "|2020-12-10| 144.7100067138672|            165.0|            141.25|             146.0|7.04475E7|\n",
      "|2020-12-11|            139.25|            151.5|135.10000610351562| 146.5500030517578|2.69808E7|\n",
      "|2020-12-14|             130.0|135.3000030517578|125.16000366210938|             135.0|1.69661E7|\n",
      "|2020-12-15|124.80000305175781|127.5999984741211|             121.5|126.69000244140625|1.09144E7|\n",
      "|2020-12-16|137.99000549316406|            142.0|124.91000366210938|125.83000183105469|2.04096E7|\n",
      "+----------+------------------+-----------------+------------------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17fdecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---+----+------+\n",
      "|Date|Close|High|Low|Open|Volume|\n",
      "+----+-----+----+---+----+------+\n",
      "|   0|    0|   0|  0|   0|     0|\n",
      "+----+-----+----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Count Number of nulls in all Column\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16b187a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL connection properties\n",
    "url = \"jdbc:mysql://localhost:3306/companies\"  # MySQL URL\n",
    "properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ee5abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do CSV\n",
    "#df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Adiciona a coluna 'nome' com valor fixo \"AAPL\"\n",
    "df_comp_nome = df.withColumn(\"nome\", lit(\"ABNB\"))\n",
    "\n",
    "# Escreve no banco MySQL\n",
    "df_comp_nome.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/companies\") \\\n",
    "    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"dbtable\", \"ABNB_historico\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2777b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---+----+------+\n",
      "|Date|Close|High|Low|Open|Volume|\n",
      "+----+-----+----+---+----+------+\n",
      "|   0|    0|   0|  0|   0|     0|\n",
      "+----+-----+----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Count Number of nulls in all Column\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce163831",
   "metadata": {},
   "source": [
    "mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72c52bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3631/736191107.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM ABNB_historico\", conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='password',\n",
    "    database='companies'\n",
    ")\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM ABNB_historico\", conn)\n",
    "df.to_csv(\"ABNB_historico_MYsql.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbbc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ABNB_Mysql= pd.read_csv(\"ABNB_historico_MYsql.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea0b881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>nome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>144.710007</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>141.250000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>70447500.0</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>139.250000</td>\n",
       "      <td>151.500000</td>\n",
       "      <td>135.100006</td>\n",
       "      <td>146.550003</td>\n",
       "      <td>26980800.0</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>125.160004</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>16966100.0</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>124.800003</td>\n",
       "      <td>127.599998</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>10914400.0</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>137.990005</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>124.910004</td>\n",
       "      <td>125.830002</td>\n",
       "      <td>20409600.0</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Close        High         Low        Open      Volume  \\\n",
       "0  2020-12-10  144.710007  165.000000  141.250000  146.000000  70447500.0   \n",
       "1  2020-12-11  139.250000  151.500000  135.100006  146.550003  26980800.0   \n",
       "2  2020-12-14  130.000000  135.300003  125.160004  135.000000  16966100.0   \n",
       "3  2020-12-15  124.800003  127.599998  121.500000  126.690002  10914400.0   \n",
       "4  2020-12-16  137.990005  142.000000  124.910004  125.830002  20409600.0   \n",
       "\n",
       "   nome  \n",
       "0  ABNB  \n",
       "1  ABNB  \n",
       "2  ABNB  \n",
       "3  ABNB  \n",
       "4  ABNB  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ABNB_Mysql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691b618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bdsp2025)",
   "language": "python",
   "name": "venv-bdsp2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
